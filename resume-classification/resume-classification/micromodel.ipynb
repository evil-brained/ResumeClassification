{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3d214a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Flatten,Dropout\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "95ae0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_var):\n",
    "    ans_ds = model_ds.predict(test_var)\n",
    "    ans_cc = model_cc.predict(test_var)\n",
    "    ans_cy = model_cy.predict(test_var)\n",
    "    ans_core = model_core.predict(test_var)\n",
    "    results = np.concatenate((ans_cc,ans_core,ans_cy,ans_ds),axis = 1)\n",
    "    results_ans = []\n",
    "    for i in results:\n",
    "        x = list(i)\n",
    "        results_ans+= [x.index(max(x))]\n",
    "    return results_ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c90a2219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\1396530780.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_test=np.asarray(X_test.iloc[:,1:]).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=20)\n",
    "le = LabelEncoder()\n",
    "oversample = RandomOverSampler()\n",
    "df = pd.read_csv('final_datasets/encoded_dataset.csv') #dataset\n",
    "#pca = PCA(n_components=20)\n",
    "#pca_values = pca.fit(df.iloc[:,3:]).singular_values_\n",
    "#df = pd.read_csv(\"data/proper_dataset.csv\")\n",
    "X = df.iloc[:,2:]\n",
    "y = le.fit_transform(df['Streams'])\n",
    "X, y= oversample.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_test=np.asarray(X_test.iloc[:,1:]).astype(np.int)\n",
    "#y_test=tensorflow.one_hot(np.asarray(y_test).astype(np.int),depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2664bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neuron = 1091\n",
    "hidden_neuron1 =512\n",
    "hidden_neuron2 = 512\n",
    "hidden_neuron3 = 512\n",
    "hidden_neuron4 = 512\n",
    "active_hidden = \"softplus\"\n",
    "active = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ff5ad23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\1262197013.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_cc = np.asarray(X_train.loc[X_train['Streams']=='cloud computing'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\1262197013.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_cy = np.asarray(X_train.loc[X_train['Streams']=='cyber security'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\1262197013.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_core = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\1262197013.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "X_train_cc = np.asarray(X_train.loc[X_train['Streams']=='cloud computing'].iloc[:,1:]).astype(np.int)\n",
    "X_train_cy = np.asarray(X_train.loc[X_train['Streams']=='cyber security'].iloc[:,1:]).astype(np.int)\n",
    "X_train_core = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n",
    "X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n",
    "\n",
    "\n",
    "X_train_cc_new = np.concatenate((X_train_cc,X_train_ds[:X_train_cc.shape[0]//5]))\n",
    "X_train_core_new = np.concatenate((X_train_core,X_train_ds[:X_train_core.shape[0]//5]))\n",
    "X_train_cy_new = np.concatenate((X_train_cy,X_train_ds[:X_train_cy.shape[0]//5]))\n",
    "X_train_ds_new = np.concatenate((X_train_ds,X_train_cc[:X_train_cc.shape[0]//5]))\n",
    "\n",
    "\n",
    "y_train_cc = np.concatenate((np.ones(X_train_cc.shape[0]),np.zeros(X_train_cc_new.shape[0]-X_train_cc.shape[0])))\n",
    "y_train_core = np.concatenate((np.ones(X_train_core.shape[0]),np.zeros(X_train_core_new.shape[0]-X_train_core.shape[0])))\n",
    "y_train_cy = np.concatenate((np.ones(X_train_cy.shape[0]),np.zeros(X_train_cy_new.shape[0]-X_train_cy.shape[0])))\n",
    "y_train_ds = np.concatenate((np.ones(X_train_ds.shape[0]),np.zeros(X_train_ds_new.shape[0]-X_train_ds.shape[0])))\n",
    "\n",
    "y_train_cc = y_train_cc.reshape(y_train_cc.shape[0],1)\n",
    "y_train_cy = y_train_cy.reshape(y_train_cy.shape[0],1)\n",
    "y_train_core = y_train_core.reshape(y_train_core.shape[0],1)\n",
    "y_train_ds = y_train_ds.reshape(y_train_ds.shape[0],1)\n",
    "\n",
    "\n",
    "#X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n",
    "\n",
    "#X_train_cc = (pca.fit(X_train_cc)).singular_values_\n",
    "#X_train_core = (pca.fit(X_train_core)).singular_values_\n",
    "#X_train_cy = (pca.fit(X_train_cy)).singular_values_\n",
    "#X_train_ds = (pca.fit(X_train_ds)).singular_values_\n",
    "    \n",
    "#y_train_cc = np.array([1 if i == 0 else 0 for i in y_train])\n",
    "#y_train_core = np.array([1 if i == 1 else 0 for i in y_train])\n",
    "#y_train_cy = np.array([1 if i == 2 else 0 for i in y_train])\n",
    "#y_train_ds = np.array([1 if i == 3 else 0 for i in y_train])\n",
    "\n",
    "\n",
    "#y_train_cc = np.broadcast_to(np.array([1]), (X_train_cc.shape[0], 1))\n",
    "#y_train_core = np.broadcast_to(np.array([1]), (X_train_core.shape[0], 1))\n",
    "#y_train_cy = np.broadcast_to(np.array([1]), (X_train_cy.shape[0], 1))\n",
    "#y_train_ds = np.broadcast_to(np.array([1]), (X_train_ds.shape[0], 1))\n",
    "\n",
    "y_test_cc = np.array([[1] if i == 0 else [0] for i in y_test])\n",
    "y_test_core = np.array([[1] if i == 1 else [0] for i in y_test])\n",
    "y_test_cy = np.array([[1] if i == 2 else [0] for i in y_test])\n",
    "y_test_ds = np.array([[1] if i == 3  else [0] for i in y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f15204c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 5ms/step - loss: 0.4144 - Accuracy: 0.8333 - precision: 0.8333 - recall: 1.0000\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2337 - Accuracy: 0.8654 - precision: 0.8609 - recall: 1.0000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1525 - Accuracy: 0.9808 - precision: 0.9774 - recall: 1.0000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1079 - Accuracy: 0.9679 - precision: 0.9630 - recall: 1.0000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0763 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0544 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0419 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0277 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0229 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0191 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0163 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0141 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0123 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0108 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0095 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0083 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0074 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0066 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0054 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0044 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0010 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.7045e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.3489e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.8610e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.5377e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.1258e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7757e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4644e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1682e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.9126e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5839e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3352e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0865e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.8621e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 5.6774e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4371e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.2415e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0553e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.8912e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7101e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5533e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.3945e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.2357e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.1095e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9758e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8459e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7379e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6105e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5027e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3990e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2944e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1958e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1034e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0102e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9212e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8402e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7601e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6822e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6063e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5393e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4681e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4004e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3374e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2819e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2177e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1553e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1046e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0488e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0003e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9483e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8989e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8563e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8079e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7628e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7216e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 5ms/step - loss: 0.5589 - Accuracy: 0.8062 - precision: 0.8366 - recall: 0.9552\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3902 - Accuracy: 0.8313 - precision: 0.8365 - recall: 0.9925\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3457 - Accuracy: 0.8375 - precision: 0.8375 - recall: 1.0000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3216 - Accuracy: 0.8188 - precision: 0.8344 - recall: 0.9776\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3041 - Accuracy: 0.8250 - precision: 0.8442 - recall: 0.9701\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3147 - Accuracy: 0.7812 - precision: 0.8613 - recall: 0.8806\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3046 - Accuracy: 0.8313 - precision: 0.8365 - recall: 0.9925\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2852 - Accuracy: 0.8125 - precision: 0.8662 - recall: 0.9179\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2792 - Accuracy: 0.7937 - precision: 0.8483 - recall: 0.9179\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2772 - Accuracy: 0.8062 - precision: 0.8323 - recall: 0.9627\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2792 - Accuracy: 0.8188 - precision: 0.8832 - recall: 0.9030\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2629 - Accuracy: 0.7937 - precision: 0.8389 - recall: 0.9328\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2627 - Accuracy: 0.7937 - precision: 0.8686 - recall: 0.8881\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2732 - Accuracy: 0.7812 - precision: 0.8322 - recall: 0.9254\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2699 - Accuracy: 0.8125 - precision: 0.9127 - recall: 0.8582\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2655 - Accuracy: 0.8250 - precision: 0.8354 - recall: 0.9851\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2669 - Accuracy: 0.8125 - precision: 0.9483 - recall: 0.8209\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2581 - Accuracy: 0.8250 - precision: 0.8354 - recall: 0.9851\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2562 - Accuracy: 0.7688 - precision: 0.8345 - recall: 0.9030\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2543 - Accuracy: 0.7625 - precision: 0.8429 - recall: 0.8806\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2472 - Accuracy: 0.7875 - precision: 0.8676 - recall: 0.8806\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2557 - Accuracy: 0.8062 - precision: 0.8552 - recall: 0.9254\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2697 - Accuracy: 0.7812 - precision: 0.8898 - recall: 0.8433\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2590 - Accuracy: 0.8125 - precision: 0.8562 - recall: 0.9328\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2615 - Accuracy: 0.7875 - precision: 0.8472 - recall: 0.9104\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2574 - Accuracy: 0.8000 - precision: 0.9113 - recall: 0.8433\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2557 - Accuracy: 0.8188 - precision: 0.8387 - recall: 0.9701\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2509 - Accuracy: 0.8062 - precision: 0.9187 - recall: 0.8433\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2581 - Accuracy: 0.8188 - precision: 0.8571 - recall: 0.9403\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2563 - Accuracy: 0.7875 - precision: 0.8676 - recall: 0.8806\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2654 - Accuracy: 0.7937 - precision: 0.8741 - recall: 0.8806\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3035 - Accuracy: 0.8125 - precision: 0.9407 - recall: 0.8284\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3628 - Accuracy: 0.8000 - precision: 0.8312 - recall: 0.9552\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2802 - Accuracy: 0.8125 - precision: 0.9643 - recall: 0.8060\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2618 - Accuracy: 0.8125 - precision: 0.8333 - recall: 0.9701\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2486 - Accuracy: 0.8125 - precision: 0.9262 - recall: 0.8433\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2503 - Accuracy: 0.8438 - precision: 0.8471 - recall: 0.9925\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2521 - Accuracy: 0.7688 - precision: 0.8760 - recall: 0.8433\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2453 - Accuracy: 0.7875 - precision: 0.8731 - recall: 0.8731\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2508 - Accuracy: 0.8062 - precision: 0.9187 - recall: 0.8433\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2589 - Accuracy: 0.8062 - precision: 0.8411 - recall: 0.9478\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2494 - Accuracy: 0.7937 - precision: 0.9174 - recall: 0.8284\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2529 - Accuracy: 0.8000 - precision: 0.8446 - recall: 0.9328\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2529 - Accuracy: 0.7812 - precision: 0.8722 - recall: 0.8657\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2573 - Accuracy: 0.8062 - precision: 0.9256 - recall: 0.8358\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2509 - Accuracy: 0.7875 - precision: 0.8289 - recall: 0.9403\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2541 - Accuracy: 0.7750 - precision: 0.8356 - recall: 0.9104\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2527 - Accuracy: 0.7688 - precision: 0.8647 - recall: 0.8582\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2490 - Accuracy: 0.7875 - precision: 0.8968 - recall: 0.8433\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2589 - Accuracy: 0.7937 - precision: 0.8582 - recall: 0.9030\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2524 - Accuracy: 0.7812 - precision: 0.8367 - recall: 0.9179\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2504 - Accuracy: 0.7625 - precision: 0.8750 - recall: 0.8358\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2492 - Accuracy: 0.8062 - precision: 0.8366 - recall: 0.9552\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2474 - Accuracy: 0.7937 - precision: 0.8344 - recall: 0.9403\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2452 - Accuracy: 0.8125 - precision: 0.9561 - recall: 0.8134\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2563 - Accuracy: 0.8375 - precision: 0.8649 - recall: 0.9552\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2576 - Accuracy: 0.8250 - precision: 0.9492 - recall: 0.8358\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2465 - Accuracy: 0.7875 - precision: 0.8333 - recall: 0.9328\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2579 - Accuracy: 0.8125 - precision: 0.8768 - recall: 0.9030\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2444 - Accuracy: 0.8188 - precision: 0.8947 - recall: 0.8881\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2533 - Accuracy: 0.8125 - precision: 0.8562 - recall: 0.9328\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2471 - Accuracy: 0.7937 - precision: 0.8976 - recall: 0.8507\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2623 - Accuracy: 0.7937 - precision: 0.9316 - recall: 0.8134\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2903 - Accuracy: 0.7750 - precision: 0.8356 - recall: 0.9104\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2475 - Accuracy: 0.8125 - precision: 0.8768 - recall: 0.9030\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2504 - Accuracy: 0.8250 - precision: 0.8442 - recall: 0.9701\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2596 - Accuracy: 0.8000 - precision: 0.9397 - recall: 0.8134\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2526 - Accuracy: 0.8188 - precision: 0.8344 - recall: 0.9776\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2482 - Accuracy: 0.7812 - precision: 0.9024 - recall: 0.8284\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2411 - Accuracy: 0.7812 - precision: 0.8414 - recall: 0.9104\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2501 - Accuracy: 0.8375 - precision: 1.0000 - recall: 0.8060\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2615 - Accuracy: 0.8188 - precision: 0.8387 - recall: 0.9701\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2549 - Accuracy: 0.8375 - precision: 0.9576 - recall: 0.8433\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2400 - Accuracy: 0.8000 - precision: 0.8923 - recall: 0.8657\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2479 - Accuracy: 0.8250 - precision: 0.8354 - recall: 0.9851\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2537 - Accuracy: 0.8188 - precision: 0.9730 - recall: 0.8060\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2494 - Accuracy: 0.8062 - precision: 0.8456 - recall: 0.9403\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2508 - Accuracy: 0.7750 - precision: 0.8267 - recall: 0.9254\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2503 - Accuracy: 0.8125 - precision: 0.9561 - recall: 0.8134\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2467 - Accuracy: 0.7937 - precision: 0.8531 - recall: 0.9104\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2516 - Accuracy: 0.7937 - precision: 0.8686 - recall: 0.8881\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2523 - Accuracy: 0.8313 - precision: 0.9908 - recall: 0.8060\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2534 - Accuracy: 0.8250 - precision: 0.8354 - recall: 0.9851\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2442 - Accuracy: 0.7750 - precision: 0.8500 - recall: 0.8881\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2477 - Accuracy: 0.7750 - precision: 0.8403 - recall: 0.9030\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2543 - Accuracy: 0.7937 - precision: 0.8741 - recall: 0.8806\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2606 - Accuracy: 0.7812 - precision: 0.8960 - recall: 0.8358\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2426 - Accuracy: 0.7750 - precision: 0.8603 - recall: 0.8731\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2456 - Accuracy: 0.7688 - precision: 0.8392 - recall: 0.8955\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2432 - Accuracy: 0.7875 - precision: 0.8623 - recall: 0.8881\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2399 - Accuracy: 0.7812 - precision: 0.8322 - recall: 0.9254\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2449 - Accuracy: 0.8250 - precision: 0.9569 - recall: 0.8284\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2397 - Accuracy: 0.8000 - precision: 0.9048 - recall: 0.8507\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2466 - Accuracy: 0.8375 - precision: 0.8375 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2411 - Accuracy: 0.7750 - precision: 0.8952 - recall: 0.8284\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2514 - Accuracy: 0.7875 - precision: 0.9098 - recall: 0.8284\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2473 - Accuracy: 0.8313 - precision: 0.8365 - recall: 0.9925\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2592 - Accuracy: 0.8375 - precision: 0.9909 - recall: 0.8134\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2515 - Accuracy: 0.7625 - precision: 0.8529 - recall: 0.8657\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2514 - Accuracy: 0.8000 - precision: 0.8312 - recall: 0.9552\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 5ms/step - loss: 0.5360 - Accuracy: 0.8025 - precision: 0.8289 - recall: 0.9618\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3353 - Accuracy: 0.9045 - precision: 0.8973 - recall: 1.0000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1943 - Accuracy: 0.8790 - precision: 0.8733 - recall: 1.0000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1351 - Accuracy: 0.9745 - precision: 0.9704 - recall: 1.0000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1042 - Accuracy: 0.9809 - precision: 0.9776 - recall: 1.0000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0792 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0636 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0510 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0426 - Accuracy: 0.9936 - precision: 0.9924 - recall: 1.0000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0361 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0250 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0214 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0187 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0162 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0142 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0126 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0114 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0101 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0091 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0082 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0074 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0068 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0033 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0014 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0014 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0010 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.7591e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.4061e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.0338e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.6730e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3689e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.0658e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7593e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4759e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.2122e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.9697e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.7229e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5319e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.2809e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0809e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.8781e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.6976e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5127e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3443e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.1782e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.0183e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.8643e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7153e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5773e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4381e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3118e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1882e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0639e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9572e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8374e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7345e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6356e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5359e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4483e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3513e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2686e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1803e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1002e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0223e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9566e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8695e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7980e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7353e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6661e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5962e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5345e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 4ms/step - loss: 0.4410 - Accuracy: 0.8188 - precision: 0.8571 - recall: 0.9403   \n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2696 - Accuracy: 0.8875 - precision: 0.8816 - recall: 1.0000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1871 - Accuracy: 0.9187 - precision: 0.9116 - recall: 1.0000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1281 - Accuracy: 0.9812 - precision: 0.9781 - recall: 1.0000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0936 - Accuracy: 0.9875 - precision: 0.9853 - recall: 1.0000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0729 - Accuracy: 0.9937 - precision: 0.9926 - recall: 1.0000\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0585 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0477 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0395 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0320 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0240 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0206 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0178 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0155 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0137 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0124 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0109 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0099 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0089 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0082 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0073 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0067 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0062 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0057 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0039 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0010 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.7976e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.4279e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.0718e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.8467e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4681e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.1706e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8733e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6217e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.3751e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1178e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.8968e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.6905e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4592e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2743e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0677e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9502e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.6990e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5432e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3717e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.2164e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0669e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9362e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7807e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6603e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5266e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4142e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2863e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.1823e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0644e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9479e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8435e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7606e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6781e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5601e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4806e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3916e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3139e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2239e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1463e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0774e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0010e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9388e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8595e-04 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245ed269280>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cc = Sequential(name=\"ANN-for-resume-classification-cc\")   \n",
    "model_cc.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_cc.add(Dropout(.5, input_shape=(input_neuron,)))\n",
    "model_cc.add(Dense(hidden_neuron1, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_cc.add(Dense(64, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_cc.add(Dense(8, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_cc.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_cc.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_cc.fit(X_train_cc_new,\n",
    "          y_train_cc,\n",
    "          batch_size=10,\n",
    "          epochs=200,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "\n",
    "model_core = Sequential(name=\"ANN-for-resume-classification-core\")\n",
    "model_core.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_core.add(Dropout(.1, input_shape=(input_neuron,)))\n",
    "model_core.add(Dense(hidden_neuron2, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_core.add(Dense(64, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_core.add(Dense(8, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_core.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_core.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_core.fit(X_train_core_new,\n",
    "          y_train_core,\n",
    "          batch_size=10,\n",
    "          epochs=200,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "model_cy = Sequential(name=\"ANN-for-resume-classification-cy\")\n",
    "model_cy.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "#model_cy.add(Dropout(.5, input_shape=(input_neuron,)))\n",
    "model_cy.add(Dense(hidden_neuron3, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_cy.add(Dense(64, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_cy.add(Dense(8, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_cy.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_cy.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_cy.fit(X_train_cy_new,\n",
    "          y_train_cy,\n",
    "          batch_size=10,\n",
    "          epochs=200,\n",
    "          verbose='auto',\n",
    "         )\n",
    "\n",
    "model_ds = Sequential(name=\"ANN-for-resume-classification-ds\")\n",
    "model_ds.add(Input(shape=(input_neuron,), name='Input-Layer'))\n",
    "\n",
    "#model_ds.add(Dropout(.2, input_shape=(input_neuron,)))\n",
    "model_ds.add(Dense(hidden_neuron4, activation=active_hidden, name='Hidden-Layer'))\n",
    "#model_ds.add(Dense(64, activation='softplus', name='Hidden-Layer-2'))\n",
    "#model_ds.add(Dense(8, activation='softplus', name='Hidden-Layer-3'))\n",
    "model_ds.add(Dense(1, activation=active, name='Output-Layer'))\n",
    "\n",
    "\n",
    "model_ds.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['Accuracy', 'Precision', 'Recall'],\n",
    "              loss_weights=None,\n",
    "              weighted_metrics=None,\n",
    "              run_eagerly=None,\n",
    "              steps_per_execution=None\n",
    "              )\n",
    "\n",
    "model_ds.fit(X_train_ds_new,\n",
    "          y_train_ds,\n",
    "          batch_size=10,\n",
    "          epochs=200,\n",
    "          verbose='auto',\n",
    "         )\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "da169465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "+--------------+--------------+--------------+----------------+-----------------+\n",
      "|      cc      |     core     |      cy      |       ds       |       ans       |\n",
      "+--------------+--------------+--------------+----------------+-----------------+\n",
      "| [0.8213074]  | [0.9816336]  | [0.37626913] |  [0.9783252]   |       core      |\n",
      "| [0.99998295] |  [0.999965]  | [0.9963078]  |  [0.76770306]  | cloud computing |\n",
      "| [0.40991855] | [0.97375727] | [0.19207615] |  [0.99570215]  |       core      |\n",
      "| [0.8058762]  | [0.95100063] | [0.99969876] |  [0.9914314]   |  cyber security |\n",
      "| [0.99998754] | [0.99950874] | [0.89927834] |  [0.78906626]  | cloud computing |\n",
      "| [0.93411404] | [0.99693066] | [0.8379079]  |  [0.92124707]  |       core      |\n",
      "| [0.99992347] | [0.99997187] | [0.9975984]  |  [0.99789953]  |   data science  |\n",
      "| [0.9099098]  | [0.99549747] | [0.87840354] |  [0.99828345]  |       core      |\n",
      "| [0.9818854]  | [0.99165136] | [0.92550975] |  [0.9996074]   |       core      |\n",
      "| [0.9999344]  | [0.8874103]  | [0.99229795] |  [0.03300049]  | cloud computing |\n",
      "| [0.9998627]  | [0.97541505] | [0.5614536]  |  [0.00171549]  | cloud computing |\n",
      "| [0.59272254] | [0.9289226]  | [0.9992142]  |  [0.94661224]  |  cyber security |\n",
      "| [0.8058762]  | [0.95100063] | [0.99969876] |  [0.9914314]   |  cyber security |\n",
      "| [0.91483706] | [0.94016016] | [0.65471727] |  [0.9868293]   |       core      |\n",
      "| [0.9999959]  | [0.9996453]  | [0.9875374]  |  [0.00026857]  | cloud computing |\n",
      "| [0.7363964]  | [0.9230219]  | [0.8763042]  |  [0.9109051]   | cloud computing |\n",
      "| [0.8548918]  |  [0.998156]  | [0.79057795] |  [0.99996066]  |   data science  |\n",
      "|  [0.723197]  | [0.99980456] | [0.9999916]  |  [0.9999077]   |  cyber security |\n",
      "| [0.6811909]  |  [0.897486]  | [0.01376483] |  [0.9931242]   |       core      |\n",
      "| [0.9999994]  | [0.9987422]  | [0.9999969]  |  [0.02882605]  | cloud computing |\n",
      "| [0.15280971] |  [0.997659]  | [0.53464675] |  [0.99999493]  |   data science  |\n",
      "| [0.99899876] | [0.99734473] | [0.9990671]  |  [0.98941237]  |   data science  |\n",
      "| [0.20039679] |  [0.99373]   | [0.9999702]  |  [0.99999136]  |  cyber security |\n",
      "| [0.9994672]  | [0.99916816] | [0.99950576] |  [0.9979926]   |       core      |\n",
      "| [0.9572837]  | [0.9993577]  | [0.9602104]  |  [0.9999176]   |   data science  |\n",
      "| [0.99990255] | [0.97814834] | [0.05728293] |  [0.00036611]  | cloud computing |\n",
      "| [0.26469848] | [0.9867974]  | [0.17815909] |  [0.9945672]   |   data science  |\n",
      "|  [0.977262]  |  [0.988889]  | [0.95398694] |  [0.5027093]   |       core      |\n",
      "| [0.9921218]  | [0.99080414] | [0.5802436]  |  [0.9850214]   |   data science  |\n",
      "| [0.9849618]  | [0.9999042]  | [0.9999568]  |  [0.9999969]   |  cyber security |\n",
      "| [0.47914112] | [0.97889614] | [0.69769895] |  [0.9998964]   |   data science  |\n",
      "| [0.9999996]  | [0.9998529]  | [0.9911966]  |  [0.5240558]   | cloud computing |\n",
      "| [0.9849618]  | [0.9999042]  | [0.9999568]  |  [0.9999969]   |  cyber security |\n",
      "| [0.9999169]  |  [0.998384]  | [0.8902392]  |  [0.9161446]   | cloud computing |\n",
      "| [0.2874644]  | [0.8036804]  | [0.07571115] |  [0.88630176]  |       core      |\n",
      "| [0.8344986]  | [0.8816356]  | [0.9997142]  |  [0.37737802]  |  cyber security |\n",
      "| [0.9999906]  | [0.9997298]  | [0.99988794] |  [0.99906564]  | cloud computing |\n",
      "| [0.99990255] | [0.97814834] | [0.05728293] |  [0.00036611]  | cloud computing |\n",
      "| [0.7596851]  |  [0.992484]  | [0.6255624]  |  [0.98852557]  |   data science  |\n",
      "| [0.9849618]  | [0.9999042]  | [0.9999568]  |  [0.9999969]   |  cyber security |\n",
      "| [0.9849618]  | [0.9999042]  | [0.9999568]  |  [0.9999969]   |  cyber security |\n",
      "| [0.8922306]  | [0.9579951]  | [0.99980634] |  [0.91701597]  |  cyber security |\n",
      "| [0.9999971]  | [0.9968847]  | [0.99746066] |   [0.000355]   | cloud computing |\n",
      "| [0.92611235] | [0.9999991]  | [0.99891084] |  [0.99999875]  |   data science  |\n",
      "| [0.9878224]  | [0.99718946] | [0.99991214] |   [0.813882]   |  cyber security |\n",
      "| [0.99990803] | [0.9980415]  | [0.9999996]  |  [0.9800197]   |  cyber security |\n",
      "| [0.92931134] | [0.9992499]  | [0.78598326] |  [0.9996286]   |   data science  |\n",
      "| [0.02729155] | [0.9930334]  | [0.0222536]  |  [0.9982088]   |       core      |\n",
      "| [0.9997794]  | [0.96191263] | [0.9311135]  |  [0.00167315]  | cloud computing |\n",
      "| [0.99986374] | [0.9990539]  | [0.99999976] |  [0.9905326]   |  cyber security |\n",
      "| [0.05310278] | [0.93640834] | [0.11627334] |  [0.9979843]   |       core      |\n",
      "| [0.01103575] | [0.99997824] | [0.98830056] |      [1.]      |   data science  |\n",
      "| [0.76466966] | [0.9996577]  | [0.91006154] |  [0.9999867]   |   data science  |\n",
      "| [0.9999512]  | [0.99962485] | [0.9997681]  |  [0.41001534]  | cloud computing |\n",
      "| [0.9865674]  | [0.88685054] | [0.06923631] |  [0.09741773]  |       core      |\n",
      "| [0.9999963]  | [0.99975497] | [0.9094083]  | [7.016917e-05] | cloud computing |\n",
      "| [0.8891055]  | [0.97037524] | [0.94534856] |  [0.94178444]  |       core      |\n",
      "| [0.02729155] | [0.9930334]  | [0.0222536]  |  [0.9982088]   |       core      |\n",
      "|     [1.]     | [0.9999874]  | [0.99999994] |  [0.00915887]  | cloud computing |\n",
      "| [0.9997231]  | [0.99979925] | [0.9999994]  |  [0.9901176]   |  cyber security |\n",
      "| [0.9997552]  | [0.95509624] | [0.40475905] |  [0.9048063]   | cloud computing |\n",
      "|  [0.990089]  | [0.97611785] | [0.96819156] |  [0.43047228]  |       core      |\n",
      "| [0.9878224]  | [0.99718946] | [0.99991214] |   [0.813882]   |  cyber security |\n",
      "| [0.59272254] | [0.9289226]  | [0.9992142]  |  [0.94661224]  |  cyber security |\n",
      "| [0.35316154] | [0.9252555]  | [0.99928874] |  [0.9926322]   |  cyber security |\n",
      "| [0.06268395] | [0.99992704] | [0.9999996]  |      [1.]      |  cyber security |\n",
      "| [0.20277222] | [0.9353632]  | [0.6034435]  |   [0.999843]   |   data science  |\n",
      "| [0.98829263] | [0.9766965]  | [0.97906184] |  [0.9926033]   |       core      |\n",
      "| [0.9997523]  | [0.9834215]  | [0.9920456]  |  [0.7601142]   | cloud computing |\n",
      "| [0.9787119]  | [0.9918782]  | [0.93331945] |  [0.92319906]  |       core      |\n",
      "|  [0.999976]  | [0.98632485] | [0.9956021]  |  [0.00026188]  | cloud computing |\n",
      "| [0.8310504]  | [0.9950359]  | [0.8534279]  |  [0.9754928]   |       core      |\n",
      "| [0.7894457]  | [0.9945998]  | [0.83048785] |  [0.98794806]  |       core      |\n",
      "| [0.9789712]  | [0.9768923]  | [0.09300242] |  [0.97873515]  |   data science  |\n",
      "| [0.9995836]  | [0.9918909]  | [0.6321062]  |  [0.00192219]  | cloud computing |\n",
      "| [0.98986644] | [0.9943397]  | [0.99281234] |  [0.9199695]   |  cyber security |\n",
      "| [0.41180873] | [0.9949002]  | [0.48477957] |  [0.9860057]   |   data science  |\n",
      "|  [0.99963]   | [0.9939228]  | [0.98095226] |  [0.9578105]   |       core      |\n",
      "| [0.50848484] | [0.9964621]  | [0.04940858] |  [0.9999698]   |   data science  |\n",
      "| [0.3701321]  | [0.9168322]  | [0.5820257]  |  [0.9911067]   |       core      |\n",
      "| [0.9994762]  | [0.8251238]  | [0.19193925] |  [0.6957118]   | cloud computing |\n",
      "| [0.99998736] | [0.99374986] | [0.75219256] |  [0.00066753]  | cloud computing |\n",
      "| [0.99868816] | [0.99972713] | [0.9999863]  |  [0.99709344]  |  cyber security |\n",
      "| [0.05868176] | [0.91927254] | [0.39631546] |  [0.99726146]  |       core      |\n",
      "| [0.99587256] | [0.9989801]  | [0.88836217] |  [0.9998731]   |   data science  |\n",
      "| [0.68836784] | [0.9980812]  | [0.6024549]  |      [1.]      |   data science  |\n",
      "| [0.7953593]  | [0.98572195] | [0.8727661]  |  [0.9364093]   |       core      |\n",
      "| [0.5773168]  | [0.9946249]  | [0.20225792] |  [0.99932396]  |   data science  |\n",
      "|  [0.999976]  | [0.98632485] | [0.9956021]  |  [0.00026188]  | cloud computing |\n",
      "| [0.76008636] | [0.96377724] | [0.9742017]  |  [0.8839002]   |       core      |\n",
      "| [0.9947116]  | [0.90639526] | [0.9525324]  |  [0.6878836]   |       core      |\n",
      "| [0.8856037]  | [0.9553945]  | [0.84423035] |  [0.79066265]  |       core      |\n",
      "|  [0.943726]  | [0.99579877] | [0.9978602]  |  [0.9729815]   |       core      |\n",
      "| [0.97868437] |  [0.942935]  | [0.9999961]  |  [0.93090725]  |  cyber security |\n",
      "| [0.99981445] | [0.99946433] | [0.9765481]  |  [0.4377187]   |       core      |\n",
      "| [0.9984469]  | [0.96413153] | [0.88554597] |  [0.99239844]  |   data science  |\n",
      "| [0.78783154] | [0.99776787] | [0.9999775]  |  [0.99774075]  |  cyber security |\n",
      "| [0.9997552]  | [0.95509624] | [0.40475905] |  [0.9048063]   | cloud computing |\n",
      "| [0.99996287] | [0.9998275]  | [0.9998529]  |  [0.99936986]  |       core      |\n",
      "| [0.99955267] | [0.84153455] | [0.01594536] |  [0.99989194]  | cloud computing |\n",
      "| [0.77678853] | [0.9514461]  | [0.7583301]  |  [0.9838135]   |       core      |\n",
      "| [0.28056872] | [0.9760244]  | [0.9992488]  |  [0.9997875]   |  cyber security |\n",
      "| [0.98138636] | [0.9858897]  | [0.98370224] |  [0.89160854]  |       core      |\n",
      "| [0.01313149] | [0.86785764] | [0.1800481]  |  [0.9954569]   |   data science  |\n",
      "| [0.8925811]  | [0.9928799]  | [0.57064223] |  [0.88780284]  |       core      |\n",
      "| [0.9999432]  | [0.9883812]  | [0.9913395]  |  [0.7066655]   | cloud computing |\n",
      "| [0.91011363] | [0.97835517] |  [0.81141]   |  [0.8511171]   |       core      |\n",
      "| [0.9998627]  | [0.97541505] | [0.5614536]  |  [0.00171549]  | cloud computing |\n",
      "| [0.9603229]  | [0.99824333] | [0.99997133] |  [0.99957776]  |  cyber security |\n",
      "| [0.9997976]  | [0.9999846]  | [0.9648674]  |   [0.99894]    |   data science  |\n",
      "| [0.7194356]  | [0.9767696]  | [0.3350419]  |  [0.5848638]   |   data science  |\n",
      "| [0.8544638]  |  [0.998765]  | [0.9177881]  |  [0.9174689]   |   data science  |\n",
      "| [0.08778445] | [0.99168396] | [0.99997914] |  [0.99999934]  |  cyber security |\n",
      "| [0.01483067] | [0.9012178]  | [0.1518711]  |  [0.9999939]   |   data science  |\n",
      "| [0.37549135] | [0.99612254] | [0.99992436] |  [0.9999998]   |  cyber security |\n",
      "| [0.00116327] | [0.9796679]  | [0.53151166] |      [1.]      |   data science  |\n",
      "| [0.78783154] | [0.99776787] | [0.9999775]  |  [0.99774075]  |  cyber security |\n",
      "| [0.8095824]  | [0.90343004] | [0.7167508]  |  [0.99845994]  |       core      |\n",
      "| [0.9999169]  |  [0.998384]  | [0.8902392]  |  [0.9161446]   | cloud computing |\n",
      "| [0.99990803] | [0.9980415]  | [0.9999996]  |  [0.9800197]   |  cyber security |\n",
      "| [0.00339715] | [0.7545431]  | [0.9995623]  |  [0.9992962]   |  cyber security |\n",
      "| [0.9997523]  | [0.9834215]  | [0.9920456]  |  [0.7601142]   | cloud computing |\n",
      "| [0.54672325] | [0.99636096] |  [0.733912]  |  [0.99814355]  |       core      |\n",
      "| [0.9997552]  | [0.95509624] | [0.40475905] |  [0.9048063]   | cloud computing |\n",
      "| [0.04718223] |  [0.951469]  | [0.47589362] |  [0.99891627]  |   data science  |\n",
      "| [0.9999432]  | [0.9883812]  | [0.9913395]  |  [0.7066655]   | cloud computing |\n",
      "| [0.97527647] | [0.9994721]  | [0.9092213]  |  [0.7437812]   |       core      |\n",
      "| [0.77988046] | [0.8719679]  | [0.99992526] |  [0.81736016]  |  cyber security |\n",
      "| [0.99264574] | [0.9793918]  | [0.4973091]  |  [0.9981671]   |       core      |\n",
      "| [0.26961294] | [0.80912083] | [0.22845916] |  [0.8936988]   |       core      |\n",
      "+--------------+--------------+--------------+----------------+-----------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "ans_ds = model_ds.predict(X_test)\n",
    "ans_cc = model_cc.predict(X_test)\n",
    "ans_cy = model_cy.predict(X_test)\n",
    "ans_core = model_core.predict(X_test)\n",
    "ans = []\n",
    "for x in y_test:\n",
    "    if x == 0:\n",
    "        ans.append(\"cloud computing\")\n",
    "    if x == 1:\n",
    "        ans.append(\"core\")\n",
    "    if x == 2:\n",
    "        ans.append(\"cyber security\")\n",
    "    if x == 3:\n",
    "        ans.append(\"data science\")\n",
    "table = PrettyTable()\n",
    "table.add_column(\"cc\", ans_cc)\n",
    "table.add_column(\"core\", ans_core)\n",
    "table.add_column(\"cy\", ans_cy)\n",
    "table.add_column(\"ds\", ans_ds)\n",
    "table.add_column(\"ans\", ans)\n",
    "print(table)\n",
    "ans = []\n",
    "for x in y_test:\n",
    "    ans.append(x)\n",
    "    #if x == [1,0,0,0]:\n",
    "    #    ans.append(0)\n",
    "    #if x == [0,1,0,0]:\n",
    "    #    ans.append(1)\n",
    "    #if x == [0,0,1,0]:\n",
    "    #    ans.append(2)\n",
    "    #if x == [0,0,0,1]:\n",
    "    #    ans.append(3)\n",
    "\n",
    "y_pred = model_predict(X_test)\n",
    "score = accuracy_score(ans, y_pred,normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "da6fecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6230769230769231\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da860501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\712259025.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_cc = np.asarray(X_train.loc[X_train['Streams']=='cloud computing'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\712259025.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_cy = np.asarray(X_train.loc[X_train['Streams']=='cyber security'].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\712259025.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_core = np.asarray(X_train.loc[X_train['Streams']==\"core\"].iloc[:,1:]).astype(np.int)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14428\\712259025.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "X_train_cc = np.asarray(X_train.loc[X_train['Streams']=='cloud computing'].iloc[:,1:]).astype(np.int)\n",
    "X_train_cy = np.asarray(X_train.loc[X_train['Streams']=='cyber security'].iloc[:,1:]).astype(np.int)\n",
    "X_train_core = np.asarray(X_train.loc[X_train['Streams']==\"core\"].iloc[:,1:]).astype(np.int)\n",
    "X_train_ds = np.asarray(X_train.loc[X_train['Streams']=='data science'].iloc[:,1:]).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7288f304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 1091)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "476b41d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 1091)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa11a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 1091)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_core.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9ed6f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 1091)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0788c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = np.array([1,2,3,4,5])\n",
    "rand.reshape(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc84ce6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, -1,  1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1,\n",
       "        1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1,  1,\n",
       "       -1,  1, -1, -1,  1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1,\n",
       "       -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "       -1, -1, -1,  1, -1,  1, -1, -1, -1,  1, -1,  1], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "clf_cc = OneClassSVM(gamma='auto').fit(X_train_cc)\n",
    "clf_cc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d0ce6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,\n",
       "        1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
       "       -1,  1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,\n",
       "        1,  1,  1, -1,  1, -1,  1,  1,  1, -1, -1, -1, -1, -1,  1,  1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_core = OneClassSVM(gamma='auto').fit(X_train_core)\n",
    "clf_core.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d1b84c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1,\n",
       "        1, -1, -1,  1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
       "       -1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,\n",
       "        1,  1,  1, -1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1,  1,  1, -1,\n",
       "        1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cy = OneClassSVM(gamma='auto').fit(X_train_cy)\n",
    "clf_cy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9ed67b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,\n",
       "        1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
       "       -1,  1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,\n",
       "        1,  1,  1, -1,  1, -1,  1,  1,  1, -1, -1, -1, -1, -1,  1,  1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ds = OneClassSVM(gamma='auto').fit(X_train_ds)\n",
    "clf_ds.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "608bab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 1, 1, 3, 1, 1, 2, 2, 1, 3, 0, 2, 3, 0, 2, 1, 1, 3, 1, 3,\n",
       "       3, 2, 1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 0,\n",
       "       3, 0, 2, 2, 2, 3, 1, 3, 3, 0, 2, 3, 3, 0, 1, 3, 3, 0, 1, 3, 3, 2,\n",
       "       1, 0, 2, 3, 3, 1, 2, 1, 3, 2, 3, 1, 1, 3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc793ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe753cc8db45e3262c00fe3ab824e10abbd283f1ea3cba17b9a95a6dc1eba13c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
